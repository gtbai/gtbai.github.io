<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="白广通的博客"><title>机器学习基石第八讲：Noise and Error 笔记 | Bruce's Blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习基石第八讲：Noise and Error 笔记</h1><a id="logo" href="/.">Bruce's Blog</a><p class="description">Stay hungry, stay foolish.</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-book"> 历史</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习基石第八讲：Noise and Error 笔记</h1><div class="post-meta">Feb 22, 2017<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-disqus-identifier="2017/02/22/mlfound-8/" href="/2017/02/22/mlfound-8/#disqus_thread" class="disqus-comment-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#noise-and-probablistic-target"><span class="toc-number">1.</span> <span class="toc-text">Noise and Probablistic Target</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#error-measure"><span class="toc-number">2.</span> <span class="toc-text">Error Measure</span></a></li></ol></div></div><div class="post-content"><p>今天讲的课题就是Noise and Error。其中，noise就是噪音，error就是错误，我们要研究的就是在有noise的情况下，怎么衡量这些error。</p>
<a id="more"></a>
<h2 id="noise-and-probablistic-target">Noise and Probablistic Target</h2>
<p>我们上节课已经掌握了机器学习中最重要的一项工具 - vc dimension。我们知道如果我们的hypothesis set的vc dimension是有限的，而且我们有足够多的数据，而且我们的算法又能够找到一个<span class="math inline">\(E_{in}\)</span>很小的hypothesis，那我们就大概可以说我们学到了东西。</p>
<p>今天我们就从这里出发，对于在推导vc bound中的假设，我们考虑怎样放宽它们，来让我们对vc bound的了解能够放宽到更多的问题上。</p>
<p>我们先来复习一下我们学过的learning flow： <img src="http://oky5aqxds.bkt.clouddn.com/8-1.png" alt="图8-1"></p>
<p>通过前面的学习，我们知道，好的hypothesis set是vc dimension最finite的，好的hypothesis是<span class="math inline">\(E_{in}\)</span>是最低的。经过几个礼拜的推导，我们知道在这样的情况下，我们是能够做到学习的。那如果有了noise的情况下，好像我们也还可以设计机器学习算法（例如pocket算法），但是这对我们之前理论的推导会不会产生影响呢？这就是现在我们的课题。</p>
<p>来看noise的一些例子： <img src="http://oky5aqxds.bkt.clouddn.com/8-2.png" alt="图8-2"></p>
<p><em>问题：如果customer information错了，但并没有影响它的label，这种情况下还算noise吗？</em></p>
<p>所以不管是input x还是output y，都可能有noise。那有这些noise的情况下，我们的vc bound还是不是可以很好地作用呢？</p>
<p>为了回答这个问题，我们要从vc bound的核心 - 估计罐子中橘色弹珠的比例出发：</p>
<p>之前我们研究的都是<strong>确定性（deterministic）</strong>弹珠，即：</p>
<ul>
<li>弹珠<span class="math inline">\(\mathbf{x} \sim P(\mathbf{x})\)</span></li>
<li>确定的颜色由<span class="math inline">\([f(\mathbf{x}) \neq h(\mathbf{x})]\)</span>决定</li>
</ul>
<p>而有了noise之后，我们更像是在研究<strong>非确定性（non-deterministic）</strong>的弹珠：</p>
<ul>
<li>弹珠<span class="math inline">\(\mathbf{x} \sim P(\mathbf{x})\)</span></li>
<li>不确定的颜色<span class="math inline">\([y \neq h(\mathbf{x})]\)</span>，其中<span class="math inline">\(y \sim P(y|\mathbf{x})\)</span></li>
</ul>
<p>也就是说，这个弹珠的颜色是变来变去的。比如60%的时间是绿色，40%的时间是橘色等等。但是整个罐子看，还是会有一个橘色弹珠的比例的。我们还是可以抽样，并记录抽出弹珠的瞬间橘色弹珠的比例。这种会变色的弹珠，我们称为probablistic marble。对应到学习问题中，就是有noise的情形，也就是说label会变来变去。既然我们还是可以用抽样的方式估计弹珠比例的话，那无论是deterministic还是probablistic的弹珠，vc bound都成立： <img src="http://oky5aqxds.bkt.clouddn.com/8-4.png" alt="图8-4"></p>
<p>整合一下，就是说只要我们的每个example（<span class="math inline">\((\mathbf{x}, y)\)</span>）在training和test过程中都i.i.d.地来自某个分布<span class="math inline">\(P(\mathbf{x}, y)\)</span>的话，那我们整个的vc bound的架构都是成立的。</p>
<p>我们一般把<span class="math inline">\(P(\mathbf{x}, y)\)</span>叫做<strong>target distribution</strong>：</p>
<ul>
<li>可以被看做理想的mini-target + noise
<ul>
<li>比如<span class="math inline">\(P(o|\mathbf{x}) = 0.7, P(x|\mathbf{x}) = 0.3\)</span></li>
<li>理想的mini-target <span class="math inline">\(f(\mathbf{x}) = o\)</span></li>
<li>noise的水平就是0.3</li>
</ul></li>
<li>之前用的deterministic target f是target distribution的一种特殊情况：
<ul>
<li><span class="math inline">\(P(y|\mathbf{x}) = 1\)</span>，当<span class="math inline">\(y = f(\mathbf{x})\)</span>时</li>
<li><span class="math inline">\(P(y|\mathbf{x}) = 0\)</span>，当<span class="math inline">\(y \neq f(\mathbf{x})\)</span>时</li>
</ul></li>
</ul>
<p>今后在使用target distribution时，和我们之前使用target function并没有什么不一样。</p>
<p>今后我们学习的目的就是：在那些经常出现的输入点（相对于<span class="math inline">\(P(\mathbf{x}\)</span>））而言，我们要尽量预测的准一点（相对于<span class="math inline">\(P(y|\mathbf{x})\)</span>）.</p>
<p>现在，我们有有了新的learning flow： <img src="http://oky5aqxds.bkt.clouddn.com/8-5.png" alt="图8-5"></p>
<p>这样一来，我们就解释了pocket算法，因为即使在有noise的情况下，vc bound还是成立的。</p>
<h2 id="error-measure">Error Measure</h2>
<p>在整个learning flow中，我们一直有一步，就是衡量g和f一不一样。</p>
<p>在之前，我们衡量的标准是<span class="math inline">\(E_{out}\)</span>： <span class="math display">\[ E_{out}(g) = \epsilon_{\mathbf{x} \sim P}[g(\mathbf{x}) \neq f(\mathbf{x})] \]</span></p>
<p><em>注：这里的<span class="math inline">\(\mathbf{x} \sim P\)</span>是指按照P从X中sample出<span class="math inline">\(\mathbf{x}。\)</span></em></p>
<p>更一般地说，我们要有一个衡量误差的方式：<span class="math inline">\(E(g, f)\)</span>。</p>
<p>我们之前使用的E有三个特性：</p>
<ul>
<li>out-of-sample：还没有看过，未来抽样出来的<span class="math inline">\(\mathbf{x}\)</span></li>
<li>pointwise：可以在单个<span class="math inline">\(\mathbf{x}\)</span>上衡量，然后做抽样的平均</li>
<li>classification：我们之前研究的只是classification，所以看的只是prediction是否等于target。（通常把classification error叫做‘0/1 error’）</li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://gtbai.github.io/2017/02/22/mlfound-8/" data-id="cj1c60319000qts8ft8glercn" class="article-share-link">分享到</a><div class="tags"><a href="/tags/机器学习基石/">机器学习基石</a></div><div class="post-nav"><a href="/2017/04/10/Sublime-Text中的Project/" class="pre">Sublime Text中的Project</a><a href="/2017/02/20/mlfound-7/" class="next">机器学习基石第七讲：The VC Dimension 笔记</a></div><div id="disqus_thread"><script>var disqus_shortname = 'gtbai';
var disqus_identifier = '2017/02/22/mlfound-8/';
var disqus_title = '机器学习基石第八讲：Noise and Error 笔记';
var disqus_url = 'http://gtbai.github.io/2017/02/22/mlfound-8/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//gtbai.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/日常技巧/">日常技巧</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">8</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Sublime-Text/" style="font-size: 15px;">Sublime Text</a> <a href="/tags/机器学习基石/" style="font-size: 15px;">机器学习基石</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/04/10/Sublime-Text中的Project/">Sublime Text中的Project</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/22/mlfound-8/">机器学习基石第八讲：Noise and Error 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/20/mlfound-7/">机器学习基石第七讲：The VC Dimension 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/19/mlfound-6/">机器学习基石第六讲：Theory of Generalization 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/18/mlfound-5/">机器学习基石第五讲：Training versus Testing 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/14/mlfound-4/">机器学习基石第四讲：Learning is Impossible 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/11/mlfound-3/">机器学习基石第三讲：Types of Learning 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/09/mlfound-2/">机器学习基石第二讲：Learning to Answer Yes/No 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/06/mlfound-1/">机器学习基石第一讲：The Learning Problem 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/05/hello-world/">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//gtbai.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Bruce's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a><br/><span id="busuanzi_container_site_pv"><i class="fa fa-mouse-pointer"></i><span> </span><span rel="nofollow" id="busuanzi_value_site_pv"></span></span><span> | </span><span id="busuanzi_container_site_uv"><i class="fa fa-user-circle-o"></i><span> </span><span rel="nofollow" id="busuanzi_value_site_uv"></span></span></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script></div></body></html>